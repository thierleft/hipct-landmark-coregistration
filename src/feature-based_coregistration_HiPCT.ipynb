{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Landmark-based co-registration of multi-scale HiP-CT data.\n",
    "Using ORB features, evaluate a 4x4 spatial transformation between overview and zoom datasets\n",
    "and export to Excel sheets all transformation matrices (initial, landmark, and final combined).\n",
    "Transformation coefficients can be inputed directly into Neuroglancer.\n",
    "\n",
    "Not for clinical use.\n",
    "SPDX-FileCopyrightText: 2025 University College London, UK\n",
    "SPDX-FileCopyrightText: 2025 Thierry L. Lefebvre\n",
    "SPDX-License-Identifier: MIT\n",
    "\"\"\"\n",
    "\n",
    "def register_zoom_to_overview_orb_matrix_out(\n",
    "    down_level: int,\n",
    "    overview_name: str,\n",
    "    zoom_name: str,\n",
    "    num_slices: int = None,\n",
    "    search_range: int = None,\n",
    "    verbose: bool = True,\n",
    "    use_xyz = False,\n",
    "    random_seed: int = 42,\n",
    "):\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import cv2 as cv\n",
    "    import SimpleITK as sitk\n",
    "    import hoa_tools.dataset\n",
    "    import hoa_tools.voi\n",
    "    import hoa_tools.registration\n",
    "    import random\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import xarray as xr\n",
    "    import SimpleITK as sitk\n",
    "    from hoa_tools.registration import Inventory as RegInventory\n",
    "    from typing import Any\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    base_slices = 8\n",
    "    base_range = 20\n",
    "    scale = max(1, 2 - down_level) if down_level < 2 else 1 / (down_level - 1 + 1e-5)\n",
    "    if num_slices is None:\n",
    "        num_slices = max(5, int(round(base_slices * scale)))\n",
    "    if search_range is None:\n",
    "        search_range = max(10, int(round(base_range * scale)))\n",
    "        \n",
    "\n",
    "\n",
    "    def get_matching_slice(\n",
    "        zoom_voi,\n",
    "        overview_voi,\n",
    "        zoom_slice_index: int,\n",
    "        axis: int = 0,  # 0=z, 1=y, 2=x\n",
    "        interpolator: Any = sitk.sitkLinear,\n",
    "    ) -> np.ndarray:\n",
    "        # Get transform\n",
    "        tfm = RegInventory.get_registration(\n",
    "            source_dataset=zoom_voi.dataset,\n",
    "            target_dataset=overview_voi.dataset,\n",
    "        )\n",
    "\n",
    "        # Compute physical point in zoom space\n",
    "        zoom_spacing = zoom_voi.voxel_size_um\n",
    "        zoom_origin = [\n",
    "            zoom_voi.lower_corner.z * zoom_spacing,\n",
    "            zoom_voi.lower_corner.y * zoom_spacing,\n",
    "            zoom_voi.lower_corner.x * zoom_spacing,\n",
    "        ]\n",
    "        zoom_index = [\n",
    "            zoom_voi.size.z // 2,\n",
    "            zoom_voi.size.y // 2,\n",
    "            zoom_voi.size.x // 2,\n",
    "        ]\n",
    "        zoom_index[axis] = zoom_slice_index\n",
    "        zoom_phys = [\n",
    "            zoom_origin[i] + zoom_spacing * zoom_index[i]\n",
    "            for i in range(3)\n",
    "        ]\n",
    "\n",
    "        # Transform to overview physical point\n",
    "        overview_phys = tfm.TransformPoint(zoom_phys)\n",
    "\n",
    "        # Convert to index in overview array\n",
    "        overview_spacing = overview_voi.voxel_size_um\n",
    "        overview_origin = [\n",
    "            overview_voi.lower_corner.z * overview_spacing,\n",
    "            overview_voi.lower_corner.y * overview_spacing,\n",
    "            overview_voi.lower_corner.x * overview_spacing,\n",
    "        ]\n",
    "        overview_index = [\n",
    "            int(round((overview_phys[i] - overview_origin[i]) / overview_spacing))\n",
    "            for i in range(3)\n",
    "        ]\n",
    "\n",
    "        # Safely extract 2D slice from overview VOI’s xarray\n",
    "        da = overview_voi.get_data_array()\n",
    "        dim_names = ['z', 'y', 'x']\n",
    "        sel_kwargs = {dim_names[axis]: overview_index[axis]}\n",
    "        slice_2d = da.isel(**sel_kwargs).values  # returns a 2D numpy array\n",
    "\n",
    "        return slice_2d\n",
    "\n",
    "\n",
    "    def get_slice_from_voi(voi, axis, index):\n",
    "        da = voi.dataset.data_array(downsample_level=voi.downsample_level)\n",
    "        slicers = {\n",
    "            \"x\": slice(voi.lower_corner.x, voi.upper_corner.x),\n",
    "            \"y\": slice(voi.lower_corner.y, voi.upper_corner.y),\n",
    "            \"z\": slice(voi.lower_corner.z, voi.upper_corner.z),\n",
    "        }\n",
    "        dims = ['x', 'y', 'z']\n",
    "        \n",
    "        # Replace one of the slicers with an int to get a 2D slice\n",
    "        dim = dims[axis]\n",
    "        offset = getattr(voi.lower_corner, dim)\n",
    "        slicers[dim] = offset + index\n",
    "\n",
    "        return da.isel(**slicers).values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def log(msg):\n",
    "        if verbose:\n",
    "            print(f\"[{(time.time() - start_time)/60:.2f}min] {msg}\")\n",
    " \n",
    "    def normalize_to_uint8(xr_data, sample_frac=1e-1, bins=int(1e7), clip_z=2.0, out_range=(0, 255)):\n",
    "        def sample_volume(array, frac):\n",
    "            total_voxels = np.prod(array.shape)\n",
    "            sample_size = int(total_voxels * frac)\n",
    "            stride = int((total_voxels / sample_size) ** (1/3)) + 1\n",
    "            return array[::stride, ::stride, ::stride]\n",
    "        def percentile(p):\n",
    "            return np.interp(p / 100.0, cdf, bin_edges[1:])        \n",
    "\n",
    "        sampled = sample_volume(xr_data.data, sample_frac)\n",
    "        flat_sample = sampled.ravel()\n",
    "        if hasattr(flat_sample, \"compute\"):\n",
    "            flat_sample = flat_sample.compute()\n",
    "\n",
    "\n",
    "        hist, bin_edges = np.histogram(flat_sample, bins=bins)\n",
    "        cdf = np.cumsum(hist) / np.sum(hist)\n",
    "\n",
    "        p05 = percentile(0.05)\n",
    "        p995 = percentile(99.95)\n",
    "        clipped = xr_data.clip(p05, p995)\n",
    "\n",
    "        mean = clipped.mean().compute()\n",
    "        std = clipped.std().compute()\n",
    "        zscore = (clipped - mean) / std\n",
    "        zscore = zscore.clip(-clip_z, clip_z)\n",
    "\n",
    "        norm = ((zscore + clip_z) / (2 * clip_z)) * (out_range[1] - out_range[0])\n",
    "        return norm.clip(*out_range).astype(np.uint8)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def normalize_slice_to_uint8(slice2d: np.ndarray, clip_z: float = 3.0, out_range=(0, 255)) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Normalize a 2D image slice to uint8 using z-score clipping and linear scaling.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        slice2d : np.ndarray\n",
    "            2D grayscale input image.\n",
    "        clip_z : float\n",
    "            Z-score clipping range (e.g., 2.0 means clip to [-2, 2]).\n",
    "        out_range : tuple\n",
    "            Output intensity range, usually (0, 255) for uint8.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Normalized 2D uint8 image.\n",
    "        \"\"\"\n",
    "        if slice2d.dtype != np.float32:\n",
    "            slice2d = slice2d.astype(np.float32)\n",
    "\n",
    "        mean = np.mean(slice2d)\n",
    "        std = np.std(slice2d)\n",
    "        if std == 0:\n",
    "            std = 1e-5  # avoid division by zero\n",
    "\n",
    "        zscore = (slice2d - mean) / std\n",
    "        zscore = np.clip(zscore, -clip_z, clip_z)\n",
    "\n",
    "        norm = ((zscore + clip_z) / (2 * clip_z)) * (out_range[1] - out_range[0])\n",
    "        return np.clip(norm, *out_range).astype(np.uint8)\n",
    "    \n",
    "    def match_slices_along_axis(img_zoom, img_parent, axis, slice_indices, search_range=10):\n",
    "        orb = cv.ORB_create(nfeatures=2000)\n",
    "        zoom_matches_3d = []\n",
    "        parent_matches_3d = []\n",
    "\n",
    "        for slice_idx in slice_indices:\n",
    "            if axis == 0:\n",
    "                img2 = get_matching_slice(img_zoom, img_parent, slice_idx, axis)\n",
    "                #img2 = img_parent.dataset.isel(z=slice_idx).values\n",
    "                #img2 = get_slice_from_voi(img_parent, axis, slice_idx+100)\n",
    "                plt.figure()\n",
    "                plt.imshow(img2)\n",
    "            elif axis == 1:\n",
    "                img2 = img_parent.isel(y=slice_idx).values\n",
    "            elif axis == 2:\n",
    "                img2 = img_parent.isel(x=slice_idx).values\n",
    "                \n",
    "            img2 = normalize_slice_to_uint8(img2)\n",
    "\n",
    "            kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "            if des2 is not None and len(kp2) > 1:\n",
    "                kp2, des2 = zip(*sorted(zip(kp2, des2), key=lambda x: x[0].response, reverse=True))\n",
    "                des2 = np.array(des2)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            max_good_matches = []\n",
    "            best_kp1 = None\n",
    "\n",
    "            for zoom_slice_idx in range(slice_idx - search_range, slice_idx + search_range + 1):\n",
    "                if zoom_slice_idx < 0 or zoom_slice_idx >= [img_zoom.size.z, img_zoom.size.y, img_zoom.size.x][axis]:\n",
    "                    continue\n",
    "                if axis == 0:\n",
    "                    #img1 = img_zoom.isel(z=zoom_slice_idx).values\n",
    "                    img1 = get_slice_from_voi(img_zoom, axis, slice_idx)\n",
    "                    plt.figure()\n",
    "                    plt.imshow(img1)\n",
    "                elif axis == 1:\n",
    "                    img1 = img_zoom.isel(y=zoom_slice_idx).values\n",
    "                elif axis == 2:\n",
    "                    img1 = img_zoom.isel(x=zoom_slice_idx).values\n",
    "\n",
    "                img1 = normalize_slice_to_uint8(img1)\n",
    "                kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "                if des1 is not None and len(kp1) > 1:\n",
    "                    kp1, des1 = zip(*sorted(zip(kp1, des1), key=lambda x: x[0].response, reverse=True))\n",
    "                    des1 = np.array(des1)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=False)\n",
    "                matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "                good_matches = []\n",
    "                for m_n in matches:\n",
    "                    if len(m_n) == 2:\n",
    "                        m, n = m_n\n",
    "                        if m.distance < 0.7 * n.distance:\n",
    "                            good_matches.append(m)\n",
    "\n",
    "                if len(good_matches) > len(max_good_matches):\n",
    "                    max_good_matches = good_matches\n",
    "                    best_kp1 = kp1\n",
    "                    best_zoom_slice_idx = zoom_slice_idx\n",
    "\n",
    "            if max_good_matches:\n",
    "                matched_coords_kp1 = np.array([best_kp1[m.queryIdx].pt for m in max_good_matches], dtype=np.float32)\n",
    "                matched_coords_kp2 = np.array([kp2[m.trainIdx].pt for m in max_good_matches], dtype=np.float32)\n",
    "\n",
    "                for pt1, pt2 in zip(matched_coords_kp1, matched_coords_kp2):\n",
    "                    if axis == 0:\n",
    "                        zoom_matches_3d.append([pt1[0], pt1[1], best_zoom_slice_idx])\n",
    "                        parent_matches_3d.append([pt2[0], pt2[1], slice_idx])\n",
    "                    elif axis == 1:\n",
    "                        zoom_matches_3d.append([pt1[0], best_zoom_slice_idx, pt1[1]])\n",
    "                        parent_matches_3d.append([pt2[0], slice_idx, pt2[1]])\n",
    "                    elif axis == 2:\n",
    "                        zoom_matches_3d.append([best_zoom_slice_idx, pt1[0], pt1[1]])\n",
    "                        parent_matches_3d.append([slice_idx, pt2[0], pt2[1]])\n",
    "\n",
    "        return np.array(zoom_matches_3d), np.array(parent_matches_3d)\n",
    "\n",
    "    def convert_voxel_to_physical(points_3d, sitk_image):\n",
    "        return [sitk_image.TransformIndexToPhysicalPoint([int(round(pt[2])), int(round(pt[1])), int(round(pt[0]))])\n",
    "                for pt in points_3d]\n",
    "\n",
    "    def sitk_transform_to_matrix_4x4(tfm: sitk.Transform) -> np.ndarray:\n",
    "        if not isinstance(tfm, (sitk.AffineTransform, sitk.Similarity3DTransform)):\n",
    "            raise TypeError(f\"Unsupported transform type: {type(tfm)}\")\n",
    "        matrix = np.array(tfm.GetMatrix()).reshape(3, 3)\n",
    "        translation = np.array(tfm.GetTranslation())\n",
    "        mat4x4 = np.eye(4)\n",
    "        mat4x4[:3, :3] = matrix\n",
    "        mat4x4[:3, 3] = translation\n",
    "        return mat4x4\n",
    "\n",
    "    # Step 1: Load VOIs and data arrays\n",
    "    log(\"Loading datasets\")\n",
    "    overview_dataset = hoa_tools.dataset.get_dataset(overview_name)\n",
    "    zoom_dataset = hoa_tools.dataset.get_dataset(zoom_name)\n",
    "    \n",
    "    size_xyz = [round(v / (2**down_level)) for v in zoom_dataset.data.shape]\n",
    "\n",
    "    zoom_voi = hoa_tools.voi.VOI(\n",
    "        dataset=zoom_dataset,\n",
    "        downsample_level=down_level,\n",
    "        lower_corner={\"x\": 0, \"y\": 0, \"z\": 0},\n",
    "        size={k: round(v / (2**down_level)) for k, v in zip([\"x\", \"y\", \"z\"], zoom_dataset.data.shape)}\n",
    "    )\n",
    "    overview_voi = zoom_voi.transform_to(overview_dataset)\n",
    "    #zoom_array = zoom_voi.get_data_array()\n",
    "    #overview_array = overview_voi.get_data_array()\n",
    "    #resampled_overview = overview_voi.get_data_array_on_voi(zoom_voi, interpolator=sitk.sitkNearestNeighbor)\n",
    "    #log(\"Normalizing\")\n",
    "    #img_zoom = normalize_to_uint8(zoom_array)\n",
    "    #img_parent = normalize_to_uint8(resampled_overview)\n",
    "\n",
    "    # Step 2: Match features\n",
    "    log(\"Finding feature matches\")\n",
    "    zoom_matches_all, parent_matches_all = [], []\n",
    "    for axis in range(3):\n",
    "        #slice_indices = np.linspace(search_range, size_xyz[axis] - search_range, num_slices, dtype=int)\n",
    "        base_margin = 20\n",
    "        scale = 2 - down_level\n",
    "        edge_margin = max(int(base_margin * (2 ** scale)), 20)\n",
    "\n",
    "        start = int(edge_margin)\n",
    "        end = max(int(size_xyz[axis] - edge_margin), start + 1)\n",
    "        slice_indices = np.linspace(start, end - 1, num_slices, dtype=int)\n",
    "\n",
    "        z, p = match_slices_along_axis(zoom_voi, overview_voi, axis, slice_indices, search_range)\n",
    "        zoom_matches_all.append(z)\n",
    "        parent_matches_all.append(p)\n",
    "\n",
    "    zoom_matches = np.vstack(zoom_matches_all)\n",
    "    parent_matches = np.vstack(parent_matches_all)\n",
    "\n",
    "    distances = np.linalg.norm(zoom_matches - parent_matches, axis=1)\n",
    "    mask = distances < (np.mean(distances) + 0.2 * np.std(distances))\n",
    "    zoom_matches = zoom_matches[mask]\n",
    "    parent_matches = parent_matches[mask]\n",
    "    log(f\"{len(zoom_matches)} matches retained\")\n",
    "\n",
    "    # Step 3: Compute transform in physical space\n",
    "    log(\"Computing transform in µm\")\n",
    "    zoom_img_sitk = zoom_voi.get_sitk_image()\n",
    "    overview_img_sitk = overview_voi.get_sitk_image()\n",
    "\n",
    "    pre_transform = hoa_tools.registration.Inventory.get_registration(\n",
    "        source_dataset=zoom_voi.dataset,\n",
    "        target_dataset=overview_voi.dataset\n",
    "    )\n",
    "\n",
    "    overview_img_sitk = sitk.Resample(overview_img_sitk, zoom_img_sitk, pre_transform,\n",
    "                                      sitk.sitkLinear, 0.0, overview_img_sitk.GetPixelID())\n",
    "\n",
    "    fixed = convert_voxel_to_physical(zoom_matches, zoom_img_sitk)\n",
    "    moving = convert_voxel_to_physical(parent_matches, zoom_img_sitk)\n",
    "\n",
    "    transform = sitk.LandmarkBasedTransformInitializer(\n",
    "        sitk.AffineTransform(3),\n",
    "        fixedLandmarks=np.ravel(fixed),\n",
    "        movingLandmarks=np.ravel(moving)\n",
    "    )\n",
    "\n",
    "    composite = sitk.CompositeTransform(3)\n",
    "    composite.AddTransform(pre_transform)\n",
    "    composite.AddTransform(transform)\n",
    "\n",
    "    # === Save transform matrices to CSV ===\n",
    "    log(\"Saving transform matrices to CSV\")\n",
    "\n",
    "    # Get 4x4 matrices\n",
    "    mat_pre = sitk_transform_to_matrix_4x4(pre_transform)\n",
    "    mat_landmark = sitk_transform_to_matrix_4x4(transform)\n",
    "\n",
    "    mat_combined = mat_landmark @ mat_pre\n",
    "\n",
    "    if use_xyz:\n",
    "        mat_pre = mat_pre[[2,1,0], :][:, [2,1,0,3]]\n",
    "        mat_landmark = mat_landmark[[2,1,0], :][:, [2,1,0,3]]\n",
    "        mat_combined = mat_combined[[2,1,0], :][:, [2,1,0,3]]\n",
    "        xyz_suffix = \"_xyz\"\n",
    "    else:\n",
    "        xyz_suffix = \"\"\n",
    "\n",
    "    # Save all matrices to CSV files\n",
    "    csv_pre_path = f\"{overview_name}_to_{zoom_name}_pre_transform_physical_um{xyz_suffix}.csv\"\n",
    "    csv_landmark_path = f\"{overview_name}_to_{zoom_name}_landmark_only_physical_um{xyz_suffix}.csv\"\n",
    "    csv_combined_path = f\"{overview_name}_to_{zoom_name}_combined_transform_physical_um{xyz_suffix}.csv\"\n",
    "\n",
    "    pd.DataFrame(mat_pre).to_csv(csv_pre_path, index=False, header=False)\n",
    "    pd.DataFrame(mat_landmark).to_csv(csv_landmark_path, index=False, header=False)\n",
    "    pd.DataFrame(mat_combined).to_csv(csv_combined_path, index=False, header=False)\n",
    "\n",
    "    log(f\"Transform matrices saved to {csv_pre_path}, {csv_landmark_path}, and {csv_combined_path}\")\n",
    "\n",
    "    return composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Landmark-based co-registration of multi-scale HiP-CT data.\n",
    "Using ORB features, evaluate a 4x4 spatial transformation between overview and zoom datasets\n",
    "and export to Excel sheets all transformation matrices (initial, landmark, and final combined).\n",
    "Transformation coefficients can be inputed directly into Neuroglancer.\n",
    "\n",
    "Not for clinical use.\n",
    "SPDX-FileCopyrightText: 2025 University College London, UK\n",
    "SPDX-FileCopyrightText: 2025 Thierry L. Lefebvre\n",
    "SPDX-License-Identifier: MIT\n",
    "\"\"\"\n",
    "\n",
    "def register_zoom_to_overview_orb_matrix_out(\n",
    "    down_level: int,\n",
    "    overview_name: str,\n",
    "    zoom_name: str,\n",
    "    num_slices: int = None,\n",
    "    search_range: int = None,\n",
    "    verbose: bool = True,\n",
    "    apply_transform: bool = True,\n",
    "    show_vedo: bool = True,    \n",
    "    save_picture: bool = True,\n",
    "    use_xyz = False,\n",
    "    random_seed: int = 42,\n",
    "):\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import cv2 as cv\n",
    "    import SimpleITK as sitk\n",
    "    import hoa_tools.dataset\n",
    "    import hoa_tools.voi\n",
    "    import hoa_tools.registration\n",
    "    import random\n",
    "    #import matplotlib.pyplot as plt\n",
    "    import vedo\n",
    "    from vedo import Volume, Plane, Plotter\n",
    "    vedo.settings.default_backend = \"jupyter\"  # For Jupyter Notebook plotting    \n",
    "\n",
    "    start_time = time.time()\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    base_slices = 8\n",
    "    base_range = 20\n",
    "    scale = max(1, 2 - down_level) if down_level < 2 else 1 / (down_level - 1 + 1e-5)\n",
    "    if num_slices is None:\n",
    "        num_slices = max(5, int(round(base_slices * scale)))\n",
    "    if search_range is None:\n",
    "        search_range = max(10, int(round(base_range * scale)))\n",
    "\n",
    "\n",
    "    def log(msg):\n",
    "        if verbose:\n",
    "            print(f\"[{(time.time() - start_time)/60:.2f}min] {msg}\")\n",
    "            \n",
    "    \n",
    "    def make_rgb_overlay_slice(v1s, v2s, gamma=1.0):\n",
    "        v1s = (v1s - v1s.min()) / (np.ptp(v1s) + 1e-5)\n",
    "        v2s = (v2s - v2s.min()) / (np.ptp(v2s) + 1e-5)\n",
    "        v1s = v1s**gamma\n",
    "        v2s = v2s**gamma\n",
    "        rgb = np.zeros((*v1s.shape, 3), dtype=np.float32)\n",
    "        rgb[..., 0] = v1s\n",
    "        rgb[..., 1] = v2s\n",
    "        rgb[..., 2] = v1s\n",
    "        return (np.clip(rgb, 0, 1) * 255).astype(np.uint8)\n",
    "            \n",
    "    def vedo_overlay(vol1, vol2, spacing, zoom_name, suffix, interactive, save):\n",
    "        \n",
    "\n",
    "\n",
    "        vol1 = (vol1 - vol1.min()) / (np.ptp(vol1) + 1e-5)\n",
    "        vol2 = (vol2 - vol2.min()) / (np.ptp(vol2) + 1e-5)\n",
    "        vol1_cut = vol1.copy()\n",
    "        vol2_cut = vol2.copy()\n",
    "        z, y, x = vol2.shape\n",
    "        \n",
    "        cy, cx = y // 2, x // 2\n",
    "        radius = min(cy, cx)\n",
    "\n",
    "        Y, X = np.ogrid[:y, :x]\n",
    "        circular_mask = (X - cx) ** 2 + (Y - cy) ** 2 <= radius ** 2\n",
    "        cylindrical_mask = np.broadcast_to(circular_mask, (z, y, x))\n",
    "        vol2_cut[~cylindrical_mask] = 0\n",
    "        \n",
    "\n",
    "        vol1_cut[:z//2, :y//2, x//2:] = 0\n",
    "        vol2_cut[:z//2, :y//2, x//2:] = 0\n",
    "                    \n",
    "\n",
    "\n",
    "        v1 = Volume(vol1_cut.transpose(2,1,0)).spacing(spacing).cmap([(0, 0, 0), (1, 0, 1)]).alpha([0, 0.0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8 ,1]).shade(False)#[0, 0.25, 0.45, 0.6, 1]\n",
    "        v2 = Volume(vol2_cut.transpose(2,1,0)).spacing(spacing).cmap([(0, 0, 0), (0, 1, 0)]).alpha([0, 0.0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 1]).shade(False)\n",
    "\n",
    "        z_idx = z // 2\n",
    "        y_idx = y // 2\n",
    "        x_idx = x // 2\n",
    "        sx, sy, sz = spacing\n",
    "        px = x_idx * sx\n",
    "        py = y_idx * sy\n",
    "        pz = z_idx * sz\n",
    "\n",
    "        rgb_xy = make_rgb_overlay_slice(vol1[z_idx], vol2[z_idx])\n",
    "        rgb_xz = make_rgb_overlay_slice(vol1[:, y_idx, :], vol2[:, y_idx, :]).transpose(1, 0, 2)\n",
    "        rgb_yz = make_rgb_overlay_slice(vol1[:, :, x_idx], vol2[:, :, x_idx]).transpose(1, 0, 2)\n",
    "\n",
    "        plane_xy = Plane(pos=(px, py, pz), normal=(0, 0, 1), s=(x*sx, y*sy)).texture(rgb_xy)\n",
    "        plane_xz = Plane(pos=(px, py, z*sz/2), normal=(0, 1, 0), s=(x*sx, z*sz)).texture(rgb_xz)\n",
    "        plane_yz = Plane(pos=(px, y*sy/2, z*sz/2), normal=(1, 0, 0), s=(y*sy, z*sz)).texture(rgb_yz)\n",
    "\n",
    "        plt = Plotter(bg='black', size=(1600, 1200))\n",
    "        plt.show(v1,v2, plane_xy, plane_xz, plane_yz, axes=0, interactive=interactive) #v2, plane_xy, plane_xz, plane_yz,\n",
    "\n",
    "        cx = x * sx / 2\n",
    "        cy = y * sy / 2\n",
    "        cz = z * sz / 2\n",
    "        cam_pos = (x * sx * 1.5, -y * sy * 0.5, -z * sz * 0.5)\n",
    "        plt.camera.SetPosition(cam_pos)\n",
    "        plt.camera.SetFocalPoint((cx, cy, cz))\n",
    "        plt.camera.SetViewUp((0, 0, 1))\n",
    "\n",
    "        if save:\n",
    "            fn = f\"{zoom_name}_{suffix}_registration.png\"\n",
    "            plt.screenshot(fn, scale=3)\n",
    "            if not interactive:\n",
    "                plt.close()            \n",
    "        \n",
    "    def get_slice_from_voi(voi, axis, index):\n",
    "\n",
    "        dims = ['z', 'y', 'x']\n",
    "        dim = dims[axis]\n",
    "\n",
    "        offset = getattr(voi.lower_corner, dim)\n",
    "        abs_index = offset + index\n",
    "\n",
    "        slicers = {}\n",
    "        for d in dims:\n",
    "            if d == dim:\n",
    "                slicers[d] = abs_index\n",
    "            else:\n",
    "                slicers[d] = slice(getattr(voi.lower_corner, d), getattr(voi.upper_corner, d))\n",
    "\n",
    "        da = voi.dataset.data_array(downsample_level=voi.downsample_level)\n",
    "        slice2d = da.isel(**slicers).values\n",
    "        h, w = slice2d.shape\n",
    "        cy, cx = h // 2, w // 2\n",
    "        radius = min(cy, cx)\n",
    "        y, x = np.ogrid[:h, :w]\n",
    "        mask = (x - cx) ** 2 + (y - cy) ** 2 <= radius ** 2\n",
    "\n",
    "        slice2d[~mask] = 0\n",
    "\n",
    "        return slice2d\n",
    "\n",
    "\n",
    "    def log(msg):\n",
    "        if verbose:\n",
    "            print(f\"[{(time.time() - start_time)/60:.2f}min] {msg}\")\n",
    " \n",
    "    def normalize_to_uint8(xr_data, sample_frac=1e-1, bins=int(1e7), clip_z=3.0, out_range=(0, 255)):\n",
    "        def sample_volume(array, frac):\n",
    "            total_voxels = np.prod(array.shape)\n",
    "            sample_size = int(total_voxels * frac)\n",
    "            stride = int((total_voxels / sample_size) ** (1/3)) + 1\n",
    "            return array[::stride, ::stride, ::stride]\n",
    "        def percentile(p):\n",
    "            return np.interp(p / 100.0, cdf, bin_edges[1:])        \n",
    "\n",
    "        sampled = sample_volume(xr_data.data, sample_frac)\n",
    "        flat_sample = sampled.ravel()\n",
    "        if hasattr(flat_sample, \"compute\"):\n",
    "            flat_sample = flat_sample.compute()\n",
    "\n",
    "\n",
    "        hist, bin_edges = np.histogram(flat_sample, bins=bins)\n",
    "        cdf = np.cumsum(hist) / np.sum(hist)\n",
    "\n",
    "        p05 = percentile(0.05)\n",
    "        p995 = percentile(99.95)\n",
    "        clipped = xr_data.clip(p05, p995)\n",
    "\n",
    "        mean = clipped.mean().compute()\n",
    "        std = clipped.std().compute()\n",
    "        zscore = (clipped - mean) / std\n",
    "        zscore = zscore.clip(-clip_z, clip_z)\n",
    "\n",
    "        norm = ((zscore + clip_z) / (2 * clip_z)) * (out_range[1] - out_range[0])\n",
    "        return norm.clip(*out_range).astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    def normalize_slice_to_uint8(slice2d: np.ndarray, clip_z: float = 3.0, out_range=(0, 255)) -> np.ndarray:\n",
    "\n",
    "        if slice2d.dtype != np.float32:\n",
    "            slice2d = slice2d.astype(np.float32)\n",
    "\n",
    "        valid_mask = slice2d > 0\n",
    "\n",
    "        if not np.any(valid_mask):\n",
    "            return np.zeros_like(slice2d, dtype=np.uint8)\n",
    "\n",
    "        valid_pixels = slice2d[valid_mask]\n",
    "        mean = np.mean(valid_pixels)\n",
    "        std = np.std(valid_pixels)\n",
    "        std = std if std > 1e-5 else 1e-5  # avoid division by zero\n",
    "\n",
    "        zscore = (slice2d - mean) / std\n",
    "        zscore = np.clip(zscore, -clip_z, clip_z)\n",
    "\n",
    "        norm = ((zscore + clip_z) / (2 * clip_z)) * (out_range[1] - out_range[0])\n",
    "        norm = np.clip(norm, *out_range).astype(np.uint8)\n",
    "\n",
    "        # Reapply mask: set background to 0\n",
    "        norm[~valid_mask] = 0\n",
    "\n",
    "        return norm\n",
    "\n",
    "\n",
    "    def match_slices_along_axis(img_zoom, img_parent, axis, slice_indices, search_range=10):\n",
    "        orb = cv.ORB_create(nfeatures=2000)\n",
    "        zoom_matches_3d = []\n",
    "        parent_matches_3d = []\n",
    "        slice_num = 0\n",
    "\n",
    "        for slice_idx in slice_indices:\n",
    "            slice_num+=1\n",
    "            if axis == 0:\n",
    "                img2 = img_parent.isel(z=slice_idx).values\n",
    "            elif axis == 1:\n",
    "                if slice_num<3: # Skip first two slices in XZ, YZ, with cylinder VOI mostly background\n",
    "                    continue\n",
    "                img2 = img_parent.isel(y=slice_idx).values\n",
    "\n",
    "            elif axis == 2:\n",
    "                if slice_num<3:\n",
    "                    continue\n",
    "                img2 = img_parent.isel(x=slice_idx).values\n",
    "\n",
    "            kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "            if des2 is not None and len(kp2) > 1:\n",
    "                kp2, des2 = zip(*sorted(zip(kp2, des2), key=lambda x: x[0].response, reverse=True))\n",
    "                des2 = np.array(des2)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            max_good_matches = []\n",
    "            best_kp1 = None\n",
    "\n",
    "            for zoom_slice_idx in range(slice_idx - search_range, slice_idx + search_range + 1):\n",
    "                if zoom_slice_idx < 0 or zoom_slice_idx >= [img_zoom.size.z, img_zoom.size.y, img_zoom.size.x][axis]:\n",
    "                    continue\n",
    "                    \n",
    "                img1 = get_slice_from_voi(img_zoom, axis, slice_idx)\n",
    "                img1 = normalize_slice_to_uint8(img1)\n",
    "\n",
    "                kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "                if des1 is not None and len(kp1) > 1:\n",
    "                    kp1, des1 = zip(*sorted(zip(kp1, des1), key=lambda x: x[0].response, reverse=True))\n",
    "                    des1 = np.array(des1)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=False)\n",
    "                matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "                good_matches = []\n",
    "                for m_n in matches:\n",
    "                    if len(m_n) == 2:\n",
    "                        m, n = m_n\n",
    "                        if m.distance < 0.7 * n.distance:\n",
    "                            good_matches.append(m)\n",
    "\n",
    "                if len(good_matches) > len(max_good_matches):\n",
    "                    max_good_matches = good_matches\n",
    "                    best_kp1 = kp1\n",
    "                    best_zoom_slice_idx = zoom_slice_idx\n",
    "\n",
    "            if max_good_matches:\n",
    "                matched_coords_kp1 = np.array([best_kp1[m.queryIdx].pt for m in max_good_matches], dtype=np.float32)\n",
    "                matched_coords_kp2 = np.array([kp2[m.trainIdx].pt for m in max_good_matches], dtype=np.float32)\n",
    "\n",
    "                for pt1, pt2 in zip(matched_coords_kp1, matched_coords_kp2):\n",
    "                    if axis == 0:\n",
    "                        zoom_matches_3d.append([pt1[0], pt1[1], best_zoom_slice_idx])\n",
    "                        parent_matches_3d.append([pt2[0], pt2[1], slice_idx])\n",
    "                    elif axis == 1:\n",
    "                        zoom_matches_3d.append([pt1[0], best_zoom_slice_idx, pt1[1]])\n",
    "                        parent_matches_3d.append([pt2[0], slice_idx, pt2[1]])\n",
    "                    elif axis == 2:\n",
    "                        zoom_matches_3d.append([best_zoom_slice_idx, pt1[0], pt1[1]])\n",
    "                        parent_matches_3d.append([slice_idx, pt2[0], pt2[1]])\n",
    "\n",
    "        return np.array(zoom_matches_3d), np.array(parent_matches_3d)\n",
    "\n",
    "    def convert_voxel_to_physical(points_3d, sitk_image):\n",
    "        return [sitk_image.TransformIndexToPhysicalPoint([int(round(pt[2])), int(round(pt[1])), int(round(pt[0]))])\n",
    "                for pt in points_3d]\n",
    "\n",
    "    def sitk_transform_to_matrix_4x4(tfm: sitk.Transform) -> np.ndarray:\n",
    "        if not isinstance(tfm, (sitk.AffineTransform, sitk.Similarity3DTransform)):\n",
    "            raise TypeError(f\"Unsupported transform type: {type(tfm)}\")\n",
    "        matrix = np.array(tfm.GetMatrix()).reshape(3, 3)\n",
    "        translation = np.array(tfm.GetTranslation())\n",
    "        mat4x4 = np.eye(4)\n",
    "        mat4x4[:3, :3] = matrix\n",
    "        mat4x4[:3, 3] = translation\n",
    "        return mat4x4\n",
    "\n",
    "    # Step 1: Load VOIs and data arrays\n",
    "    log(\"Loading datasets\")\n",
    "    overview_dataset = hoa_tools.dataset.get_dataset(overview_name)\n",
    "    zoom_dataset = hoa_tools.dataset.get_dataset(zoom_name)\n",
    "\n",
    "    zoom_voi = hoa_tools.voi.VOI(\n",
    "        dataset=zoom_dataset,\n",
    "        downsample_level=down_level,\n",
    "        lower_corner={\"x\": 0, \"y\": 0, \"z\": 0},\n",
    "        size={k: round(v / (2**down_level)) for k, v in zip([\"x\", \"y\", \"z\"], zoom_dataset.data.shape)}\n",
    "    )\n",
    "    overview_voi = zoom_voi.transform_to(overview_dataset)\n",
    "    resampled_overview = overview_voi.get_data_array_on_voi(zoom_voi, interpolator=sitk.sitkNearestNeighbor)\n",
    "    img_parent = normalize_to_uint8(resampled_overview)\n",
    "\n",
    "    # Step 2: Match features\n",
    "    log(\"Finding feature matches\")\n",
    "    zoom_matches_all, parent_matches_all = [], []\n",
    "    for axis in range(3):\n",
    "        size_xyz = [zoom_voi.size.z, zoom_voi.size.y, zoom_voi.size.x]\n",
    "        slice_indices = np.linspace(search_range, size_xyz[axis] - search_range, num_slices, dtype=int)\n",
    "        z, p = match_slices_along_axis(zoom_voi, img_parent, axis, slice_indices, search_range)\n",
    "        zoom_matches_all.append(z)\n",
    "        parent_matches_all.append(p)\n",
    "\n",
    "    zoom_matches = np.vstack(zoom_matches_all)\n",
    "    parent_matches = np.vstack(parent_matches_all)\n",
    "\n",
    "    distances = np.linalg.norm(zoom_matches - parent_matches, axis=1)\n",
    "    mask = distances < (np.mean(distances) + 0.2 * np.std(distances))\n",
    "    zoom_matches = zoom_matches[mask]\n",
    "    parent_matches = parent_matches[mask]\n",
    "    log(f\"{len(zoom_matches)} matches retained\")\n",
    "\n",
    "    # Step 3: Compute transform in physical space\n",
    "    log(\"Computing transform in µm\")\n",
    "    \n",
    "    zoom_size = [zoom_voi.size.z, zoom_voi.size.y, zoom_voi.size.x]\n",
    "    zoom_spacing = [zoom_voi.voxel_size_um] * 3\n",
    "    zoom_origin = [\n",
    "        zoom_voi.lower_corner.z * zoom_voi.voxel_size_um,\n",
    "        zoom_voi.lower_corner.y * zoom_voi.voxel_size_um,\n",
    "        zoom_voi.lower_corner.x * zoom_voi.voxel_size_um,\n",
    "    ]\n",
    "\n",
    "    zoom_img_sitk = sitk.Image(zoom_size, sitk.sitkUInt8)\n",
    "    zoom_img_sitk.SetSpacing(zoom_spacing)\n",
    "    zoom_img_sitk.SetOrigin(zoom_origin)\n",
    "        \n",
    "\n",
    "    pre_transform = hoa_tools.registration.Inventory.get_registration(\n",
    "        source_dataset=zoom_voi.dataset,\n",
    "        target_dataset=overview_voi.dataset\n",
    "    )\n",
    "\n",
    "    fixed = convert_voxel_to_physical(zoom_matches, zoom_img_sitk)\n",
    "    moving = convert_voxel_to_physical(parent_matches, zoom_img_sitk)\n",
    "\n",
    "    transform = sitk.LandmarkBasedTransformInitializer(\n",
    "        sitk.AffineTransform(3),\n",
    "        fixedLandmarks=np.ravel(fixed),\n",
    "        movingLandmarks=np.ravel(moving)\n",
    "    )\n",
    "\n",
    "    composite = sitk.CompositeTransform(3)\n",
    "    composite.AddTransform(pre_transform)\n",
    "    composite.AddTransform(transform)\n",
    "    \n",
    "    # STEP 6: Apply transform (optional)\n",
    "    transformed_array = None\n",
    "    if apply_transform:\n",
    "        log(\"Applying transform to overview\")\n",
    "        transformed_array = overview_voi.get_data_array_on_voi(\n",
    "            zoom_voi,\n",
    "            interpolator=sitk.sitkLinear,\n",
    "            transform=composite.GetInverse()\n",
    "        )\n",
    "\n",
    "    spacing = (1.0, 1.0, 1.0)  # isotropic default#spacing = tuple(zoom_image.GetSpacing())\n",
    "    if show_vedo or save_picture:\n",
    "        if apply_transform:\n",
    "            vedo_overlay(transformed_array.values, normalize_to_uint8(zoom_voi.get_data_array()).values, spacing, zoom_name, \"post\", show_vedo, save_picture)\n",
    "    \n",
    "\n",
    "    # === Save transform matrices to CSV ===\n",
    "    log(\"Saving transform matrices to CSV\")\n",
    "\n",
    "    # Get 4x4 matrices\n",
    "    mat_pre = sitk_transform_to_matrix_4x4(pre_transform)\n",
    "    mat_landmark = sitk_transform_to_matrix_4x4(transform)\n",
    "\n",
    "    mat_combined = mat_landmark @ mat_pre\n",
    "\n",
    "    if use_xyz:\n",
    "        mat_pre = mat_pre[[2,1,0], :][:, [2,1,0,3]]\n",
    "        mat_landmark = mat_landmark[[2,1,0], :][:, [2,1,0,3]]\n",
    "        mat_combined = mat_combined[[2,1,0], :][:, [2,1,0,3]]\n",
    "        xyz_suffix = \"_xyz\"\n",
    "    else:\n",
    "        xyz_suffix = \"\"\n",
    "\n",
    "    # Save all matrices to CSV files\n",
    "    csv_pre_path = f\"{overview_name}_to_{zoom_name}_down{down_level}_pre_transform_physical_um{xyz_suffix}.csv\"\n",
    "    csv_landmark_path = f\"{overview_name}_to_{zoom_name}_down{down_level}_landmark_only_physical_um{xyz_suffix}.csv\"\n",
    "    csv_combined_path = f\"{overview_name}_to_{zoom_name}_down{down_level}_combined_transform_physical_um{xyz_suffix}.csv\"\n",
    "\n",
    "    pd.DataFrame(mat_pre).to_csv(csv_pre_path, index=False, header=False)\n",
    "    pd.DataFrame(mat_landmark).to_csv(csv_landmark_path, index=False, header=False)\n",
    "    pd.DataFrame(mat_combined).to_csv(csv_combined_path, index=False, header=False)\n",
    "\n",
    "    log(f\"Transform matrices saved to {csv_pre_path}, {csv_landmark_path}, and {csv_combined_path}\")\n",
    "\n",
    "    return composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = register_zoom_to_overview_orb_matrix_out(\n",
    "    overview_name=\"OVERVIEW SCAN ID\",\n",
    "    zoom_name=\"ZOOM SCAN ID\",\n",
    "    verbose=True,\n",
    "    apply_transform=False,\n",
    "    show_vedo=False,    \n",
    "    save_picture = False,\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hipctanalysis11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
