{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f64232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Landmark-based co-registration of multi-scale HiP-CT data.\n",
    "Using ORB features, evaluate a 4x4 spatial transformation between overview and zoom datasets\n",
    "and export to Excel sheets all transformation matrices (initial, landmark, and final combined).\n",
    "Transformation coefficients can be inputed directly into Neuroglancer.\n",
    "\n",
    "Not for clinical use.\n",
    "SPDX-FileCopyrightText: 2025 University College London, UK\n",
    "SPDX-FileCopyrightText: 2025 Thierry L. Lefebvre\n",
    "SPDX-License-Identifier: MIT\n",
    "\"\"\"\n",
    "\n",
    "def register_zoom_to_overview_orb_matrix_out(\n",
    "    down_level: int,\n",
    "    overview_name: str,\n",
    "    zoom_name: str,\n",
    "    num_slices: int = 5,\n",
    "    search_range: int = 10,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import cv2 as cv\n",
    "    import SimpleITK as sitk\n",
    "    import hoa_tools.dataset\n",
    "    import hoa_tools.voi\n",
    "    import hoa_tools.registration\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    def log(msg):\n",
    "        if verbose:\n",
    "            print(f\"[{(time.time() - start_time)/60:.2f}min] {msg}\")\n",
    " \n",
    "    def normalize_slice_to_uint8(img_2d, clip_z=3.0):\n",
    "        p_low, p_high = np.percentile(img_2d, [0.05, 99.995])\n",
    "        img_clipped = np.clip(img_2d, p_low, p_high)\n",
    "        mean = np.mean(img_clipped)\n",
    "        std = np.std(img_clipped)\n",
    "        zscore = (img_clipped - mean) / std\n",
    "        zscore = np.clip(zscore, -clip_z, clip_z)\n",
    "        norm = ((zscore + clip_z) / (2 * clip_z))\n",
    "        return (norm * 255).astype(np.uint8)\n",
    "    \n",
    "\n",
    "    def match_slices_along_axis(img_zoom, img_parent, axis, slice_indices, search_range=10):\n",
    "        orb = cv.ORB_create(nfeatures=2000)\n",
    "        zoom_matches_3d = []\n",
    "        parent_matches_3d = []\n",
    "\n",
    "        for slice_idx in slice_indices:\n",
    "            if axis == 0:\n",
    "                img2 = img_parent.isel(z=slice_idx).values\n",
    "            elif axis == 1:\n",
    "                img2 = img_parent.isel(y=slice_idx).values\n",
    "            elif axis == 2:\n",
    "                img2 = img_parent.isel(x=slice_idx).values\n",
    "\n",
    "            img2  =  normalize_slice_to_uint8(img2)\n",
    "\n",
    "            kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "            if des2 is None or len(kp2) < 2:\n",
    "                continue\n",
    "\n",
    "            max_good_matches = []\n",
    "            best_kp1 = None\n",
    "\n",
    "            for zoom_slice_idx in range(slice_idx - search_range, slice_idx + search_range + 1):\n",
    "                if zoom_slice_idx < 0 or zoom_slice_idx >= img_zoom.shape[axis]:\n",
    "                    continue\n",
    "                if axis == 0:\n",
    "                    img1 = img_zoom.isel(z=zoom_slice_idx).values\n",
    "                elif axis == 1:\n",
    "                    img1 = img_zoom.isel(y=zoom_slice_idx).values\n",
    "                elif axis == 2:\n",
    "                    img1 = img_zoom.isel(x=zoom_slice_idx).values\n",
    "\n",
    "                img1  =  normalize_slice_to_uint8(img1)\n",
    "\n",
    "\n",
    "                kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "                if des1 is None or len(kp1) < 2:\n",
    "                    continue\n",
    "\n",
    "                bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=False)\n",
    "                matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "                good_matches = []\n",
    "                for m_n in matches:\n",
    "                    if len(m_n) == 2:\n",
    "                        m, n = m_n\n",
    "                        if m.distance < 0.7 * n.distance:\n",
    "                            good_matches.append(m)\n",
    "\n",
    "                if len(good_matches) > len(max_good_matches):\n",
    "                    max_good_matches = good_matches\n",
    "                    best_kp1 = kp1\n",
    "                    best_zoom_slice_idx = zoom_slice_idx\n",
    "\n",
    "            if max_good_matches:\n",
    "                matched_coords_kp1 = np.array([best_kp1[m.queryIdx].pt for m in max_good_matches], dtype=np.float32)\n",
    "                matched_coords_kp2 = np.array([kp2[m.trainIdx].pt for m in max_good_matches], dtype=np.float32)\n",
    "\n",
    "                for pt1, pt2 in zip(matched_coords_kp1, matched_coords_kp2):\n",
    "                    if axis == 0:\n",
    "                        zoom_matches_3d.append([pt1[0], pt1[1], best_zoom_slice_idx])\n",
    "                        parent_matches_3d.append([pt2[0], pt2[1], slice_idx])\n",
    "                    elif axis == 1:\n",
    "                        zoom_matches_3d.append([pt1[0], best_zoom_slice_idx, pt1[1]])\n",
    "                        parent_matches_3d.append([pt2[0], slice_idx, pt2[1]])\n",
    "                    elif axis == 2:\n",
    "                        zoom_matches_3d.append([best_zoom_slice_idx, pt1[0], pt1[1]])\n",
    "                        parent_matches_3d.append([slice_idx, pt2[0], pt2[1]])\n",
    "\n",
    "        return np.array(zoom_matches_3d), np.array(parent_matches_3d)\n",
    "\n",
    "    def convert_voxel_to_physical(points_3d, sitk_image):\n",
    "        return [sitk_image.TransformIndexToPhysicalPoint([int(round(pt[2])), int(round(pt[1])), int(round(pt[0]))])\n",
    "                for pt in points_3d]\n",
    "\n",
    "    def sitk_transform_to_matrix_4x4(tfm: sitk.Transform) -> np.ndarray:\n",
    "        if not isinstance(tfm, (sitk.AffineTransform, sitk.Similarity3DTransform)):\n",
    "            raise TypeError(f\"Unsupported transform type: {type(tfm)}\")\n",
    "        matrix = np.array(tfm.GetMatrix()).reshape(3, 3)\n",
    "        translation = np.array(tfm.GetTranslation())\n",
    "        mat4x4 = np.eye(4)\n",
    "        mat4x4[:3, :3] = matrix\n",
    "        mat4x4[:3, 3] = translation\n",
    "        return mat4x4\n",
    "\n",
    "    # Step 1: Load VOIs and data arrays\n",
    "    log(\"Loading datasets\")\n",
    "    overview_dataset = hoa_tools.dataset.get_dataset(overview_name)\n",
    "    zoom_dataset = hoa_tools.dataset.get_dataset(zoom_name)\n",
    "\n",
    "    zoom_voi = hoa_tools.voi.VOI(\n",
    "        dataset=zoom_dataset,\n",
    "        downsample_level=down_level,\n",
    "        lower_corner={\"x\": 0, \"y\": 0, \"z\": 0},\n",
    "        size={k: round(v / (2**down_level)) for k, v in zip([\"x\", \"y\", \"z\"], zoom_dataset.data.shape)}\n",
    "    )\n",
    "    overview_voi = zoom_voi.transform_to(overview_dataset)\n",
    "    img_zoom = zoom_voi.get_data_array()\n",
    "    #overview_array = overview_voi.get_data_array()\n",
    "    img_parent = overview_voi.get_data_array_on_voi(zoom_voi, interpolator=sitk.sitkNearestNeighbor)\n",
    "\n",
    "    #log(\"Normalizing\")\n",
    "    #img_zoom = normalize_to_uint8(zoom_array)\n",
    "    #img_parent = normalize_to_uint8(resampled_overview)\n",
    "    \n",
    "\n",
    "    # Step 2: Match features\n",
    "    log(\"Finding feature matches\")\n",
    "    zoom_matches_all, parent_matches_all = [], []\n",
    "    for axis in range(3):\n",
    "        slice_indices = np.linspace(search_range, img_zoom.shape[axis] - search_range, num_slices, dtype=int)\n",
    "        z, p = match_slices_along_axis(img_zoom, img_parent, axis, slice_indices, search_range)\n",
    "        zoom_matches_all.append(z)\n",
    "        parent_matches_all.append(p)\n",
    "\n",
    "    zoom_matches = np.vstack(zoom_matches_all)\n",
    "    parent_matches = np.vstack(parent_matches_all)\n",
    "\n",
    "    distances = np.linalg.norm(zoom_matches - parent_matches, axis=1)\n",
    "    mask = distances < (np.mean(distances) + 0.2 * np.std(distances))\n",
    "    zoom_matches = zoom_matches[mask]\n",
    "    parent_matches = parent_matches[mask]\n",
    "    log(f\"{len(zoom_matches)} matches retained\")\n",
    "\n",
    "    # Step 3: Compute transform in physical space\n",
    "    log(\"Computing transform in µm\")\n",
    "    zoom_img_sitk = zoom_voi.get_sitk_image()\n",
    "    overview_img_sitk = overview_voi.get_sitk_image()\n",
    "\n",
    "    pre_transform = hoa_tools.registration.Inventory.get_registration(\n",
    "        source_dataset=zoom_voi.dataset,\n",
    "        target_dataset=overview_voi.dataset\n",
    "    )\n",
    "\n",
    "    overview_img_sitk = sitk.Resample(overview_img_sitk, zoom_img_sitk, pre_transform,\n",
    "                                      sitk.sitkLinear, 0.0, overview_img_sitk.GetPixelID())\n",
    "\n",
    "    fixed = convert_voxel_to_physical(zoom_matches, zoom_img_sitk)\n",
    "    moving = convert_voxel_to_physical(parent_matches, zoom_img_sitk)\n",
    "\n",
    "    transform = sitk.LandmarkBasedTransformInitializer(\n",
    "        sitk.AffineTransform(3),\n",
    "        fixedLandmarks=np.ravel(fixed),\n",
    "        movingLandmarks=np.ravel(moving)\n",
    "    )\n",
    "\n",
    "    composite = sitk.CompositeTransform(3)\n",
    "    composite.AddTransform(pre_transform)\n",
    "    composite.AddTransform(transform)\n",
    "\n",
    "    # === Save transform matrices to Excel ===\n",
    "    log(\"Saving transform matrices to Excel\")\n",
    "\n",
    "\n",
    "    # Get 4x4 matrices\n",
    "    mat_pre = sitk_transform_to_matrix_4x4(pre_transform)\n",
    "    mat_landmark = sitk_transform_to_matrix_4x4(transform)\n",
    "\n",
    "    mat_combined = mat_landmark @ mat_pre\n",
    "\n",
    "    # Save all matrices to Excel\n",
    "    excel_path = f\"{overview_name}_to_{zoom_name}_transforms_physical_um.xlsx\"\n",
    "    with pd.ExcelWriter(excel_path) as writer:\n",
    "        pd.DataFrame(mat_pre).to_excel(writer, sheet_name=\"Pre_Transform\", index=False)\n",
    "        pd.DataFrame(mat_landmark).to_excel(writer, sheet_name=\"Landmark_Only\", index=False)\n",
    "        pd.DataFrame(mat_combined).to_excel(writer, sheet_name=\"Combined_Transform\", index=False)\n",
    "\n",
    "    log(f\"Transform matrices saved to {excel_path}\")\n",
    "\n",
    "    return composite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8211511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucemlef/.conda/envs/hipctanalysis11/lib/python3.11/site-packages/hoa_tools/dataset.py:253: UserWarning: Did not find target dataset E24-15904_breast_tumor_complete-organ_16.548um_bm18 in dataset inventory. Not adding E24-15904_breast_tumor_VOI-1_4.259um_bm18 to registration inventory.\n",
      "  warnings.warn(\n",
      "/home/ucemlef/.conda/envs/hipctanalysis11/lib/python3.11/site-packages/hoa_tools/dataset.py:253: UserWarning: Did not find target dataset E24-15904_breast_tumor_complete-organ_16.548um_bm18 in dataset inventory. Not adding E24-15904_breast_tumor_VOI-3_4.259um_bm18 to registration inventory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00min] Loading datasets\n",
      "[0.52min] Normalizing\n",
      "[0.88min] Finding feature matches\n",
      "[1.66min] 1794 matches retained\n",
      "[1.66min] Computing transform in µm\n",
      "[2.18min] Saving transform matrices to Excel\n",
      "[2.18min] Transform matrices saved to SH1_skull_complete-organ_16.545um_bm18_to_SH1_skull_VOI-09_2.20um_bm18_transforms_physical_um.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Only run for private data\n",
    "import pathlib\n",
    "import hoa_tools.dataset\n",
    "hoa_tools.dataset.change_metadata_directory(pathlib.Path('/hdd2/thierry/private-hoa-metadata/metadata/'))\n",
    "\n",
    "# Adapt your file names you wish to co-register\n",
    "transform = register_zoom_to_overview_orb_matrix_out(\n",
    "    down_level=2,\n",
    "    overview_name=\"SH1_skull_complete-organ_16.545um_bm18\",\n",
    "    zoom_name=\"SH1_skull_VOI-09_2.20um_bm18\",   \n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hipctanalysis11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
